{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Semi-parametric Survival Analysis Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by Michael Wamberg & Bjarke Hastrup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The equivalent poisson model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Survival function:  $$S(t)=exp\\left(-\\int_0^t \\lambda(u)du\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cox proportional hazard:$$\\lambda_{ij} =\\lambda_{j} \\exp(\\mathbf{x}_{i}^{T}\\boldsymbol{\\beta})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likelihood contribution from i'th individual, who dies or is censored in j'th time interval:    $\\nu_i=1$ for death, 0 otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "L_i(\\boldsymbol{\\beta},\\boldsymbol{\\lambda} | D_{i})\n",
    "&= (\\lambda_{j} \\exp(\\mathbf{x}_{i}^{T}\\boldsymbol{\\beta}))^{\\delta_{ij}\\nu_{i}} \\exp \\left\\{ - \\delta_{ij} \\left[ \\lambda_{j}(y_{i} - s_{j-1}) + \\sum^{j-1}_{g=1} \\lambda_{g}(s_{g} - s_{g-1}) \\right] \\exp(\\mathbf{x}_{i}^{T}\\boldsymbol{\\beta}) \\right\\}\\\\\n",
    " &= \\prod^{j}_{g=1} \\exp \\left\\{ - \\lambda_{g} t_{i,g} \\exp(\\mathbf{x}_{i}^{T}\\boldsymbol{\\beta}) \\right\\} (\\lambda_{g} t_{i,g} \\exp(\\mathbf{x}_{i}^{T}\\boldsymbol{\\beta}))^{\\delta_{i,g} \\nu_{i}} \\big/ (\\delta_{i,g} \\nu_{i})!\\\\\n",
    "\\end{align*}\n",
    "\n",
    "We recognize this as poisson likelihood: $\\frac{\\mu e^{-\\mu}}{k!}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\log(\\mu_{i,g})= \\log(t_{i,g}) + \\log(\\lambda_{g}) + \\mathbf{x}_{i}^{T}\\boldsymbol{\\beta}\\\\\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import random\n",
    "random.seed(1100038344)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import statsmodels\n",
    "import pystan\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#from pandas_ods_reader import read_ods\n",
    "\n",
    "# matplotlib options\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (9, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>goal_time_h</th>\n",
       "      <th>goal_time_a</th>\n",
       "      <th>finished</th>\n",
       "      <th>red_cards_h</th>\n",
       "      <th>red_cards_a</th>\n",
       "      <th>BbAv&gt;2.5</th>\n",
       "      <th>PSCH</th>\n",
       "      <th>PSCD</th>\n",
       "      <th>PSCA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E0</td>\n",
       "      <td>10/08/2018</td>\n",
       "      <td>Man United</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3,83</td>\n",
       "      <td>91</td>\n",
       "      <td>94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.03</td>\n",
       "      <td>1.55</td>\n",
       "      <td>4.07</td>\n",
       "      <td>7.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E0</td>\n",
       "      <td>11/08/2018</td>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>Cardiff</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>24,91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1.88</td>\n",
       "      <td>3.61</td>\n",
       "      <td>4.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E0</td>\n",
       "      <td>11/08/2018</td>\n",
       "      <td>Fulham</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41,80</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.62</td>\n",
       "      <td>3.38</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E0</td>\n",
       "      <td>11/08/2018</td>\n",
       "      <td>Huddersfield</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34,45,80</td>\n",
       "      <td>93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.98</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.95</td>\n",
       "      <td>1.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E0</td>\n",
       "      <td>11/08/2018</td>\n",
       "      <td>Newcastle</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>8,18</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.01</td>\n",
       "      <td>4.74</td>\n",
       "      <td>3.53</td>\n",
       "      <td>1.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Div        Date      HomeTeam        AwayTeam  FTHG  FTAG goal_time_h  \\\n",
       "0  E0  10/08/2018    Man United       Leicester     2     1        3,83   \n",
       "1  E0  11/08/2018   Bournemouth         Cardiff     2     0       24,91   \n",
       "2  E0  11/08/2018        Fulham  Crystal Palace     0     2         NaN   \n",
       "3  E0  11/08/2018  Huddersfield         Chelsea     0     3         NaN   \n",
       "4  E0  11/08/2018     Newcastle       Tottenham     1     2          11   \n",
       "\n",
       "  goal_time_a  finished red_cards_h red_cards_a  BbAv>2.5  PSCH  PSCD  PSCA  \n",
       "0          91        94         NaN         NaN      2.03  1.55  4.07  7.69  \n",
       "1         NaN        95         NaN         NaN      1.98  1.88  3.61  4.70  \n",
       "2       41,80        95         NaN         NaN      1.95  2.62  3.38  2.90  \n",
       "3    34,45,80        93         NaN         NaN      1.98  7.24  3.95  1.58  \n",
       "4        8,18        95         NaN         NaN      2.01  4.74  3.53  1.89  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('all_leagues_collected_clean.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data description:\n",
    "\n",
    "Div = League Division\n",
    "\n",
    "Date = Match Date (dd/mm/yy)\n",
    "\n",
    "HomeTeam = Home Team\n",
    "\n",
    "AwayTeam = Away Team\n",
    "\n",
    "FTHG = Full Time Home Team Goals\n",
    "\n",
    "FTAG = Full Time Away Team Goals\n",
    "\n",
    "goal_time_h = times for home team goals\n",
    "\n",
    "goal_time_a = times for away team goals\n",
    "\n",
    "finished = played number of minutes\n",
    "\n",
    "red_cars_h = red card times for the home team\n",
    "\n",
    "red_cards_a = red card times for the away team\n",
    "\n",
    "BbAv>2.5 = Betbrain average over 2.5 goals\n",
    "\n",
    "PSCH = Pinnacle home win odds\n",
    "\n",
    "PSCD = Pinnacle draw odds\n",
    "\n",
    "PSCA = Pinnacle away win odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matches per league"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_por = df[df['Div'].str.contains(\"P1\")].reset_index()\n",
    "matches_eng = df[df['Div'].str.contains(\"E0\")].reset_index()\n",
    "matches_ita = df[df['Div'].str.contains(\"I1\")].reset_index() \n",
    "\n",
    "print(\"The dataset contains\", len(matches_por), \"matches from Portugal,\", len(matches_eng), \"matches from England and\", len(matches_ita), \"matches from Italy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FTG_por = matches_por[\"FTHG\"] + matches_por[\"FTAG\"] # total number of goals per match in Portugal\n",
    "FTG_eng = matches_eng[\"FTHG\"] + matches_eng[\"FTAG\"] # total number of goals per match in England\n",
    "FTG_ita = matches_ita[\"FTHG\"] + matches_ita[\"FTAG\"] # # total number of goals per match in Italy\n",
    "\n",
    "FTG_por_cumsum, FTG_eng_cumsum, FTG_ita_cumsum = [], [], []\n",
    "FTG_por_av, FTG_eng_av, FTG_ita_av = [], [], []\n",
    "\n",
    "for i in range(len(FTG_por)):\n",
    "    FTG_por_cumsum.append(FTG_por[i])\n",
    "    FTG_por_av.append(np.sum(FTG_por_cumsum) / (i+1))\n",
    "\n",
    "for i in range(len(FTG_eng)):\n",
    "    FTG_eng_cumsum.append(FTG_eng[i])\n",
    "    FTG_eng_av.append(np.sum(FTG_eng_cumsum) / (i+1))\n",
    "\n",
    "    FTG_ita_cumsum.append(FTG_ita[i])\n",
    "    FTG_ita_av.append(np.sum(FTG_ita_cumsum) / (i+1))\n",
    "    \n",
    "plt.title(\"Average goals in the leagues\")\n",
    "plt.ylabel(\"Average goals per match\")\n",
    "plt.xlabel(\"Matches\")\n",
    "plt.plot(FTG_por_av, label=\"Portugal, Primeira Liga\")\n",
    "plt.plot(FTG_eng_av, label=\"England, Premier League\")\n",
    "plt.plot(FTG_ita_av, label=\"Italy, Serie A\")\n",
    "plt.legend()\n",
    "\n",
    "print(\"The average number of goals from the 2017/18 and 2018/19 seasons in Portugal:\", np.mean(FTG_por))\n",
    "print(\"The average number of goals from the 2017/18 and 2018/19 seasons in England:\", np.mean(FTG_eng))\n",
    "print(\"The average number of goals from the 2017/18 and 2018/19 seasons in Portugal:\", np.mean(FTG_ita))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are extracting the times for the first goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start by recording the NaN values\n",
    "ikke_nan_h = df['goal_time_h'].isnull() == False\n",
    "ikke_nan_a = df['goal_time_a'].isnull() == False\n",
    "\n",
    "# function for finding second goal\n",
    "def second_smallest(goal_times):\n",
    "    m1, m2 = float('inf'), float('inf')\n",
    "    for x in goal_times:\n",
    "        if x <= m1:\n",
    "            m1, m2 = x, m1\n",
    "        elif x < m2:\n",
    "            m2 = x\n",
    "    return m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['t'] = df['finished'] # for first goal times\n",
    "df['t1'] = df['finished'] # for first home goal times\n",
    "\n",
    "df['dead'] = 0 # for censoring related to first goal\n",
    "df['dead1'] = 0 # for censoring related to first home goal\n",
    "\n",
    "# For second home goal times. Notice here that the observation only starts if we get a first goal in the match. Thus, we initialize with NaN\n",
    "df['t2'] = np.nan\n",
    "df['dead2'] = np.nan\n",
    "\n",
    "for i in range(len(df)):\n",
    "    if ikke_nan_h[i] == True:\n",
    "        df.loc[i,'dead'] = 1\n",
    "        string = df.loc[i,'goal_time_h']\n",
    "        try:\n",
    "            substr = string[:string.index(\",\")]\n",
    "            df.loc[i, 't1_h'] = float(substr)\n",
    "        except:\n",
    "            substr = df.loc[i,'goal_time_h']\n",
    "            df.loc[i,'t1_h'] = float(substr)\n",
    "    \n",
    "    if ikke_nan_a[i] == True:\n",
    "        df.loc[i,'dead'] = 1\n",
    "        string = df.loc[i,'goal_time_a']\n",
    "        try:\n",
    "            substr = string[:string.index(\",\")]\n",
    "            df.loc[i,'t1_a'] = float(substr)\n",
    "        except:\n",
    "            substr = df.loc[i,'goal_time_a']\n",
    "            df.loc[i,'t1_a'] = float(substr)\n",
    "            \n",
    "    # adding first goal times\n",
    "    first_goal = min(df.loc[i,'t1_h'], df.loc[i,'t1_a'])\n",
    "    \n",
    "    if first_goal < df.loc[i,'t']:\n",
    "        df.loc[i,'t'] = first_goal\n",
    "    \n",
    "    if df.loc[i,'t'] == df.loc[i,'t1_h']: # only counting the home goals\n",
    "        df.loc[i,'t1'] = df.loc[i,'t']\n",
    "        df.loc[i,'dead1'] = 1\n",
    "    \n",
    "    # adding second goal times\n",
    "    if df.loc[i, 'dead'] == 1: \n",
    "        \n",
    "        # we got a first goal, so now we can activate t2 and dead2\n",
    "        df.loc[i,'dead2'] = 0\n",
    "        df.loc[i,'t2'] = df.loc[i, 'finished']\n",
    "        \n",
    "        if df.loc[i, 'dead1'] == 1: # in the case where the first goal was a home goal\n",
    "            time_split_h = df.loc[i, 'goal_time_h'].split(\",\")\n",
    "        \n",
    "            n_goals_h = len(time_split_h)\n",
    "                    \n",
    "            if n_goals_h > 1:\n",
    "                if ikke_nan_a[i] == True:\n",
    "                    time_split_a = df.loc[i, 'goal_time_a'].split(\",\")\n",
    "                    if time_split_a[0] > time_split_h[1]:\n",
    "                        df.loc[i,'dead2'] = 1\n",
    "                        df.loc[i,'t2'] = float(time_split_h[1])\n",
    "                else:\n",
    "                    df.loc[i,'dead2'] = 1\n",
    "                    df.loc[i,'t2'] = float(time_split_h[1])\n",
    "        \n",
    "        # in the case where the first goal was a away goal\n",
    "        if df.loc[i, 'dead1'] == 0 and ikke_nan_h[i] == True and ikke_nan_a[i] == True:\n",
    "            time_split_h = df.loc[i, 'goal_time_h'].split(\",\")\n",
    "            time_split_a = df.loc[i, 'goal_time_a'].split(\",\")\n",
    "            \n",
    "            if len(time_split_a) == 1:\n",
    "                df.loc[i,'dead2'] = 1\n",
    "                df.loc[i,'t2'] = float(time_split_h[0])\n",
    "            elif time_split_h[0] < time_split_a[1]:\n",
    "                df.loc[i,'dead2'] = 1\n",
    "                df.loc[i,'t2'] = float(time_split_h[0])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_split_h = df.loc[1, 'goal_time_h'].split(\",\")\n",
    "n_goals_h = len(time_split_h)\n",
    "n_goals_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1, 'goal_time_h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>goal_time_h</th>\n",
       "      <th>goal_time_a</th>\n",
       "      <th>finished</th>\n",
       "      <th>red_cards_h</th>\n",
       "      <th>...</th>\n",
       "      <th>PSCD</th>\n",
       "      <th>PSCA</th>\n",
       "      <th>t</th>\n",
       "      <th>t1</th>\n",
       "      <th>dead</th>\n",
       "      <th>dead1</th>\n",
       "      <th>t2</th>\n",
       "      <th>dead2</th>\n",
       "      <th>t1_h</th>\n",
       "      <th>t1_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E0</td>\n",
       "      <td>10/08/2018</td>\n",
       "      <td>Man United</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3,83</td>\n",
       "      <td>91</td>\n",
       "      <td>94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.07</td>\n",
       "      <td>7.69</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E0</td>\n",
       "      <td>11/08/2018</td>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>Cardiff</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>24,91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.61</td>\n",
       "      <td>4.70</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E0</td>\n",
       "      <td>11/08/2018</td>\n",
       "      <td>Fulham</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41,80</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.38</td>\n",
       "      <td>2.90</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E0</td>\n",
       "      <td>11/08/2018</td>\n",
       "      <td>Huddersfield</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34,45,80</td>\n",
       "      <td>93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.95</td>\n",
       "      <td>1.58</td>\n",
       "      <td>93.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E0</td>\n",
       "      <td>11/08/2018</td>\n",
       "      <td>Newcastle</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>8,18</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.53</td>\n",
       "      <td>1.89</td>\n",
       "      <td>8.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>E0</td>\n",
       "      <td>11/08/2018</td>\n",
       "      <td>Watford</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>35,54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.22</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>E0</td>\n",
       "      <td>11/08/2018</td>\n",
       "      <td>Wolves</td>\n",
       "      <td>Everton</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>44,80</td>\n",
       "      <td>17,67</td>\n",
       "      <td>94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.23</td>\n",
       "      <td>3.32</td>\n",
       "      <td>17.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>E0</td>\n",
       "      <td>12/08/2018</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Man City</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14,64</td>\n",
       "      <td>94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.13</td>\n",
       "      <td>1.81</td>\n",
       "      <td>94.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>E0</td>\n",
       "      <td>12/08/2018</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>West Ham</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>19,45,53,88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.95</td>\n",
       "      <td>12.00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>E0</td>\n",
       "      <td>12/08/2018</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Burnley</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4.65</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Div        Date      HomeTeam        AwayTeam  FTHG  FTAG  goal_time_h  \\\n",
       "0  E0  10/08/2018    Man United       Leicester     2     1         3,83   \n",
       "1  E0  11/08/2018   Bournemouth         Cardiff     2     0        24,91   \n",
       "2  E0  11/08/2018        Fulham  Crystal Palace     0     2          NaN   \n",
       "3  E0  11/08/2018  Huddersfield         Chelsea     0     3          NaN   \n",
       "4  E0  11/08/2018     Newcastle       Tottenham     1     2           11   \n",
       "5  E0  11/08/2018       Watford        Brighton     2     0        35,54   \n",
       "6  E0  11/08/2018        Wolves         Everton     2     2        44,80   \n",
       "7  E0  12/08/2018       Arsenal        Man City     0     2          NaN   \n",
       "8  E0  12/08/2018     Liverpool        West Ham     4     0  19,45,53,88   \n",
       "9  E0  12/08/2018   Southampton         Burnley     0     0          NaN   \n",
       "\n",
       "  goal_time_a  finished red_cards_h  ...  PSCD   PSCA     t    t1  dead  \\\n",
       "0          91        94         NaN  ...  4.07   7.69   3.0   3.0     1   \n",
       "1         NaN        95         NaN  ...  3.61   4.70  24.0  24.0     1   \n",
       "2       41,80        95         NaN  ...  3.38   2.90  95.0  95.0     1   \n",
       "3    34,45,80        93         NaN  ...  3.95   1.58  93.0  93.0     1   \n",
       "4        8,18        95         NaN  ...  3.53   1.89   8.0  95.0     1   \n",
       "5         NaN        94         NaN  ...  3.08   3.22  35.0  35.0     1   \n",
       "6       17,67        94         NaN  ...  3.23   3.32  17.0  94.0     1   \n",
       "7       14,64        94         NaN  ...  4.13   1.81  94.0  94.0     1   \n",
       "8         NaN        93         NaN  ...  6.95  12.00  19.0  19.0     1   \n",
       "9         NaN        95         NaN  ...  3.19   4.65  95.0  95.0     0   \n",
       "\n",
       "   dead1    t2  dead2  t1_h  t1_a  \n",
       "0      1  83.0    1.0   3.0  91.0  \n",
       "1      1  91.0    1.0  24.0   NaN  \n",
       "2      0  95.0    0.0   NaN  41.0  \n",
       "3      0  93.0    0.0   NaN  34.0  \n",
       "4      0  11.0    1.0  11.0   8.0  \n",
       "5      1  54.0    1.0  35.0   NaN  \n",
       "6      0  44.0    1.0  44.0  17.0  \n",
       "7      0  94.0    0.0   NaN  14.0  \n",
       "8      1  45.0    1.0  19.0   NaN  \n",
       "9      0   NaN    NaN   NaN   NaN  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can look at when the first goal is generally scored in the three leagues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_por = df[df['Div'].str.contains(\"P1\")].reset_index()\n",
    "matches_eng = df[df['Div'].str.contains(\"E0\")].reset_index()\n",
    "matches_ita = df[df['Div'].str.contains(\"I1\")].reset_index()\n",
    "\n",
    "nondead_por = matches_por['dead'] == 1\n",
    "nondead_eng = matches_eng['dead'] == 1\n",
    "nondead_ita = matches_ita['dead'] == 1\n",
    "\n",
    "matches_por_nondead = matches_por[nondead_por]\n",
    "matches_eng_nondead = matches_eng[nondead_eng]\n",
    "matches_ita_nondead = matches_ita[nondead_ita]\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.subplots_adjust(hspace = 0.5)\n",
    "\n",
    "plt.subplot(2, 2, 1, )\n",
    "plt.title(\"Portugal\")\n",
    "plt.hist(matches_por_nondead['t'], bins=15, alpha=0.4)\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title(\"England\")\n",
    "plt.hist(matches_eng_nondead['t'], bins=15, alpha=0.4)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.title(\"Italy\")\n",
    "plt.hist(matches_ita_nondead['t'], bins=15, alpha=0.4)\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Minutes\")\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.title(\"All leagues\")\n",
    "plt.hist(matches_por_nondead['t'], bins=15, alpha=0.4)\n",
    "plt.hist(matches_eng_nondead['t'], bins=15, alpha=0.4)\n",
    "plt.hist(matches_ita_nondead['t'], bins=15, alpha=0.4)\n",
    "plt.xlabel(\"Minutes\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we setup an skill feature based on the available odds in the dataset. To do this most accurately, we must pay attention to how the bookmaker (Pinnacle) apply his margin. The odds quoted by Pinnacle on some match is related to the probabilities of the possible outcomes in this match. These probabilities do not add to 100% though, and the amount by which they exceed 100% constitutes Pinnacle's margin. Removing this margin should therefore reveal their true assessment of the match. Typically a greater margin is applied to the higher odds, since people prefer longshots compared to short odds - this is known as the favourite-longshot bias. Thus, the margin is removed relative to the size of odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_odds(PSCH, PSCD, PSCA):\n",
    "    \"\"\"\n",
    "    Normalise odds to probabilities by odds margin.\n",
    "    margin weights in proportion to the size of the odds\n",
    "    \"\"\"\n",
    "    probs = [1. / odds for odds in (PSCH, PSCD, PSCA)]\n",
    "    margin = sum(probs)-1.\n",
    "    trueo = [1./(3.* odds/(3.-margin*odds)) for odds in (PSCH, PSCD, PSCA)]\n",
    "    \n",
    "    return trueo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_columns = ['PSCH', 'PSCD', 'PSCA']\n",
    "\n",
    "probabilities = df[odds_columns].apply(lambda row: normalise_odds(**row), axis=1)\n",
    "cols = list(['home_win_prob','draw','away_win_prob'])\n",
    "probabilities = pd.DataFrame(probabilities.values.tolist(), columns=cols)\n",
    "\n",
    "df = df.merge(\n",
    "    probabilities,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    suffixes=['', '_prob']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To confirm our added columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can look at how these probabilities match up with the actual results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add full time result column\n",
    "for i in range(len(df)):\n",
    "    if df['FTHG'][i] > df['FTAG'][i]:\n",
    "        df.loc[i,'FTR'] = 'H'\n",
    "    elif df['FTHG'][i] < df['FTAG'][i]:\n",
    "        df.loc[i,'FTR'] = 'A'\n",
    "    else:\n",
    "        df.loc[i,'FTR'] = 'D'\n",
    "        \n",
    "# discretize win probabilties\n",
    "prob_range = np.linspace(0.15, 0.90, num=15)\n",
    "prob_count = np.empty(len(prob_range))\n",
    "win_count = np.empty(len(prob_range))\n",
    "\n",
    "for i in range(len(df)):\n",
    "    for j in range(len(prob_range)-1):\n",
    "        if df['home_win_prob'][i] > prob_range[j] and df['home_win_prob'][i] < prob_range[j+1]:\n",
    "            prob_count[j] += 1\n",
    "            df.loc[i,'home_win_prob_disc'] = prob_range[j]        \n",
    "            \n",
    "        elif df['away_win_prob'][i] > prob_range[j] and df['away_win_prob'][i] < prob_range[j+1]:\n",
    "            prob_count[j] += 1\n",
    "            df.loc[i,'away_win_prob_disc'] = prob_range[j]\n",
    "\n",
    "for i in range(len(df)):\n",
    "    for j in range(len(prob_range)-1):\n",
    "        if df['home_win_prob_disc'][i] == prob_range[j] and df['FTR'][i] == 'H':\n",
    "            win_count[j] += 1\n",
    "        elif df['away_win_prob_disc'][i] == prob_range[j] and df['FTR'][i] == 'A':\n",
    "            win_count[j] += 1   \n",
    "            \n",
    "# Outcome probability implied by results\n",
    "OPIR = win_count / prob_count\n",
    "\n",
    "model = LinearRegression()\n",
    "x = OPIR[:-1].reshape((-1, 1))\n",
    "y = prob_range[:-1]\n",
    "model.fit(x, y)\n",
    "model = LinearRegression().fit(x, y)\n",
    "r_sq = model.score(x, y)\n",
    "prediction=model.predict(np.sort(x, axis=0))\n",
    "print('Coefficient of determination:', r_sq)\n",
    "\n",
    "plt.title(\"Outcome probabilities implied by Pinnacle odds versus actual results\")\n",
    "plt.xlabel(\"Outcome probability implied by Pinnacle\")\n",
    "plt.ylabel(\"Outcome probability implied by results\")\n",
    "plt.scatter(x, y)\n",
    "plt.plot(np.sort(x, axis=0),prediction, 'k--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to avoid a _absolute value function-looking_-function, we create the skill gap feature below,  which goes to zero for two teams that are considered equally likely to win the match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['skill_gap'] = np.abs(df['home_win_prob'] - df['away_win_prob'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the first goal times versus this skill gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nondead_idx = df['dead'] == 1\n",
    "df_nondead = df[df_nondead_idx]\n",
    "df_nonead_sorted_sg = df_nondead.sort_values(by=['skill_gap'])\n",
    "\n",
    "plt.title(\"First goal times versus skill gap\")\n",
    "plt.ylabel(\"First goal time\")\n",
    "plt.xlabel(\"Skill gap\")\n",
    "plt.scatter(df_nonead_sorted_sg['skill_gap'],df_nonead_sorted_sg['t'], s=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forcing our skill gap to be within range [-1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "df.loc[:, 'skill_gap'] = scaler.fit_transform(np.asarray(df.loc[:, 'skill_gap']).reshape(-1, 1))\n",
    "df.dead = df.dead.astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_patients = df.shape[0]\n",
    "patients = np.arange(n_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sort = df.sort_values(by=['t'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "blue, _, red = sns.color_palette()[:3]\n",
    "ax.hlines(patients[df_sort.dead.values == 0], 0, df_sort[df_sort.dead.values == 0].t,\n",
    "          color=blue, label='Censored');\n",
    "ax.hlines(patients[df_sort.dead.values == 1], 0, df_sort[df_sort.dead.values == 1].t,\n",
    "          color=red, label='Uncensored');\n",
    "\n",
    "ax.set_xlim(left=0);\n",
    "ax.set_xlabel('Survival time [days]');\n",
    "ax.set_ylim(-0.25, n_patients + 0.25);\n",
    "ax.legend(loc='top right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_length = 4\n",
    "interval_bounds = np.arange(0, df.t.max() + interval_length + 1, interval_length)\n",
    "n_intervals = interval_bounds.size - 1\n",
    "intervals = np.arange(n_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.hist(df[df.dead == 1].t.values, bins=interval_bounds,\n",
    "        color=red, alpha=0.5, lw=0,\n",
    "        label='Uncensored');\n",
    "ax.hist(df[df.dead == 0].t.values, bins=interval_bounds,\n",
    "        color=blue, alpha=0.5, lw=0,\n",
    "        label='Censored');\n",
    "ax.set_xlim(0, interval_bounds[-1]);\n",
    "ax.set_xlabel('Survival time [days]');\n",
    "ax.set_yticks([0, 1, 2, 3]);\n",
    "ax.set_ylabel('Number of observations');\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_period = np.floor((df.t - 0.01) / interval_length)\n",
    "\n",
    "death = np.zeros((n_patients, n_intervals))\n",
    "death[patients, last_period.astype(int)] = df.dead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exposure = np.greater_equal.outer(df.t, interval_bounds[:-1]) * interval_length\n",
    "exposure[patients, last_period.astype(int)] = df.t - interval_bounds[last_period.astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_dat = {'N': len(df),\n",
    "             'n_intervals':  n_intervals,\n",
    "             #'death_array': death_array, \n",
    "             #'meta_array':  meta_array, \n",
    "             #'expo_array':  expo_array}\n",
    "             'death':     death.astype(int),\n",
    "             'skill_gap':   np.asarray(df.skill_gap),\n",
    "             'exposure':  exposure}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#death_array = np.matrix.flatten(death)\n",
    "#expo_array = np.matrix.flatten(exposure)\n",
    "#therapy_array = np.asarray(df.therapy)\n",
    "#meta_array = np.tile(meta_array, (n_intervals, 1))\n",
    "#meta_array = meta_array.flatten('F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_array = np.matrix.flatten(death).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expo_array = np.matrix.flatten(exposure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_gap_array = np.asarray(df.skill_gap)\n",
    "skill_gap_array = np.tile(skill_gap_array, (n_intervals, 1))\n",
    "skill_gap_array = skill_gap_array.flatten('F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_id = np.arange(1,n_intervals+1)\n",
    "print(str(base_id.shape))\n",
    "base_id = np.tile(base_id, len(df))\n",
    "base_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_dat2 ={'N':      len(df),\n",
    "             'N_tot':  len(death_array),\n",
    "             'T':      n_intervals,\n",
    "             'M': 1,\n",
    "             'base_id': base_id,\n",
    "             'death_array':   death_array, \n",
    "             'x': skill_gap_array, \n",
    "             'expo':    expo_array}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expo_new  = expo_array[expo_array > 0]\n",
    "N_tot_new = len(expo_new)\n",
    "base_id_new = base_id[expo_array > 0]\n",
    "death_array_new = death_array[expo_array > 0]\n",
    "skill_gap_array_new = skill_gap_array[expo_array > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "death_dat3 ={'N':      len(df),\n",
    "             'N_tot':  N_tot_new,\n",
    "             'T':      n_intervals,\n",
    "             'M': 1,\n",
    "             'base_id': base_id_new,\n",
    "             'death_array':   death_array_new, \n",
    "             'x': skill_gap_array_new, \n",
    "             'expo':    expo_new}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_dat3['base_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stan code for equivalent poisson model using independent vague priors $\\lambda_j \\sim gamma(0.1,0.1)$. \n",
    "For covariate coeffient we have chosen $beta \\sim normal(0,2).$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survival_model=\"\"\"\n",
    "data {\n",
    "  int<lower=1> N;          // number of individuals\n",
    "  int<lower=1> N_tot;      // total number of pseudo poisson observations\n",
    "  int<lower=1> T;          // number of time intervals\n",
    "  //int<lower=0> M;        // number of covariates\n",
    "  int<lower=0, upper=T> base_id[N_tot];  // time interval index for each pseudo obs.\n",
    "  \n",
    "  int<lower=0, upper=1> death_array[N_tot];    // 1 for observed death, 0 all other cases\n",
    "  vector[N_tot] x;                             // covariates\n",
    "\n",
    "  vector<lower=0>[N_tot] expo;  // exposure time (time alive) in each interval\n",
    "}\n",
    "\n",
    "transformed data {\n",
    "  vector[N_tot] log_expo = log(expo);  // log-duration for each timepoint\n",
    "}\n",
    "parameters {\n",
    "  real beta;                       // regression coefficient\n",
    "  vector<lower=0>[T] lambda0;  // baseline hazard for each timepoint t\n",
    "}\n",
    "model {\n",
    "  beta ~ normal(0, 1);\n",
    "  lambda0 ~ gamma(0.01,0.1);\n",
    "  for (n_tot in 1:N_tot) {\n",
    "    death_array[n_tot] ~ poisson_log(log(lambda0[base_id[n_tot]]) + log_expo[n_tot]   + x[n_tot] * beta );\n",
    "  }\n",
    "  \n",
    "}\n",
    "generated quantities {\n",
    "  vector[N] log_lik;\n",
    "  int n; \n",
    "  n = 1;\n",
    "  log_lik = rep_vector(0,N);\n",
    "  \n",
    "  // log_lik for loo-psis\n",
    "  for (n_tot in 1:N_tot) { \n",
    "      log_lik[n] += poisson_log_lpmf(death_array[n_tot]| log(lambda0[base_id[n_tot]])+log_expo[n_tot]+x[n_tot]*beta );\n",
    "      \n",
    "      // increment individual count if next time interval comes before the current \n",
    "      // only because of bad programming\n",
    "      if (n_tot > 1){\n",
    "          if (base_id[n_tot] <= base_id[n_tot-1]){\n",
    "              n += 1;  \n",
    "          }\n",
    "      }\n",
    "  }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = pystan.StanModel(model_code=survival_model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = sm.sampling(data=death_dat3, algorithm=\"HMC\", seed=10, iter=500, chains=4, warmup=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa = fit.extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion: The test therapy reduces the average hazard by approximately 8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(aa['beta'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.traceplot('beta');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Psis-loo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psis import psisloo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(aa['log_lik'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood1 = aa['log_lik'].reshape(1600,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loo, loos, ks = psisloo(log_likelihood1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(loos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimated number of effective parameters\n",
    "computed_lppd = np.sum(np.log(np.mean(np.exp(log_likelihood1),axis=0)));\n",
    "pl00cv = computed_lppd - loo;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_lppd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl00cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "26 effective parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "plt.hist(ks, bins=20)\n",
    "plt.plot([0.7, 0.7],[0,50],\"b\")\n",
    "plt.xlabel(\"k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot survival function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_hazard = aa['lambda0']\n",
    "base_hazard.shape\n",
    "\n",
    "met_hazard = aa['lambda0'] * np.exp(np.atleast_2d(aa['beta']).T)\n",
    "met_hazard.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cum_hazard(hazard):\n",
    "    return (interval_length * hazard).cumsum(axis=-1)\n",
    "\n",
    "def survival(hazard):\n",
    "    return np.exp(-cum_hazard(hazard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_hpd(x, hazard, f, ax, color=None, label=None, alpha=0.05):\n",
    "    mean = f(hazard.mean(axis=0))\n",
    "    \n",
    "    percentiles = 100 * np.array([alpha / 2., 1. - alpha / 2.])\n",
    "    hpd = np.percentile(f(hazard), percentiles, axis=0)\n",
    "    \n",
    "    ax.fill_between(x, hpd[0], hpd[1], color=color, alpha=0.25)\n",
    "    ax.step(x, mean, color=color, label=label);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (hazard_ax, surv_ax) = plt.subplots(ncols=2, sharex=True, sharey=False, figsize=(16, 6))\n",
    "\n",
    "# plot_with_hpd(interval_bounds[:-1], base_hazard, cum_hazard,\n",
    "#               hazard_ax, color=blue, label='Standard')\n",
    "plot_with_hpd(interval_bounds[:-1], met_hazard, cum_hazard,\n",
    "              hazard_ax, color=red, label='TEST')\n",
    "\n",
    "hazard_ax.set_xlim(0, df.t.max());\n",
    "hazard_ax.set_xlabel('Days');\n",
    "\n",
    "hazard_ax.set_ylabel(r'Cumulative hazard, $\\int_0^t \\lambda(u)du$');\n",
    "\n",
    "hazard_ax.legend(loc=2);\n",
    "\n",
    "# plot_with_hpd(interval_bounds[:-1], base_hazard, survival,\n",
    "#               surv_ax, color=blue)\n",
    "plot_with_hpd(interval_bounds[:-1], met_hazard, survival,\n",
    "              surv_ax, color=red)\n",
    "#survivalstan.utils.plot_observed_survival(df=df[df['skill_gap'] == 0], event_col='dead', time_col='t', label='standard')\n",
    "#survivalstan.utils.plot_observed_survival(df=df[df['skill_gap'] == 1], event_col='dead', time_col='t', label='test')\n",
    "survivalstan.utils.plot_observed_survival(df=df, event_col='dead', time_col='t', label='test')\n",
    "\n",
    "surv_ax.set_xlim(0, df.t.max());\n",
    "surv_ax.set_xlabel('Days');\n",
    "\n",
    "surv_ax.set_ylabel('Survivor function $S(t)$');\n",
    "\n",
    "#fig.suptitle('Bayesian survival model');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time varying coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survival_model_time_varying=\"\"\"\n",
    "data {\n",
    "  int<lower=1> N;          // number of individuals\n",
    "  int<lower=1> N_tot;      // total number of pseudo poisson observations\n",
    "  int<lower=1> T;          // number of time intervals\n",
    "  //int<lower=0> M;        // number of covariates\n",
    "  int<lower=0, upper=40> base_id[N_tot];  // time interval index for each pseudo obs.\n",
    "  \n",
    "  int<lower=0, upper=1> death_array[N_tot];    // 1 for observed death, 0 all other cases\n",
    "  vector[N_tot] x;                             // covariates\n",
    "\n",
    "  vector<lower=0>[N_tot] expo;  // exposure time (time alive) in each interval\n",
    "}\n",
    "\n",
    "transformed data {\n",
    "  vector[N_tot] log_expo = log(expo);  // log-duration for each timepoint\n",
    "  // vector[N_tot] xx = 1-x;\n",
    "}\n",
    "parameters {\n",
    "  vector[T] beta;              // regression coefficient\n",
    "  vector<lower=0>[T] lambda0;  // baseline hazard for each timepoint t\n",
    "}\n",
    "model {\n",
    "  beta ~ normal(0, 1);\n",
    "  lambda0 ~ gamma(0.01,0.1);\n",
    "  for (n_tot in 1:N_tot) {\n",
    "    death_array[n_tot] ~ poisson_log(log(lambda0[base_id[n_tot]])+log_expo[n_tot]+x[n_tot]*beta[base_id[n_tot]]);\n",
    "  }\n",
    "  \n",
    "}\n",
    "generated quantities {\n",
    "  vector[N] log_lik;\n",
    "  int n; \n",
    "  n = 1;\n",
    "  log_lik = rep_vector(0,N);\n",
    "  \n",
    "  // log_lik for loo-psis\n",
    "  for (n_tot in 1:N_tot) { \n",
    "      log_lik[n] += poisson_log_lpmf(death_array[n_tot]| log(lambda0[base_id[n_tot]])+log_expo[n_tot]+x[n_tot]*beta );\n",
    "      \n",
    "      // increment individual count if next time interval comes before the current \n",
    "      // only because of bad programming\n",
    "      if (n_tot > 1){\n",
    "          if (base_id[n_tot] <= base_id[n_tot-1]){\n",
    "              n += 1;  \n",
    "          }\n",
    "      }\n",
    "  }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_time = pystan.StanModel(model_code=survival_model_time_varying);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_time = sm_time.sampling(data=death_dat3, algorithm=\"HMC\", seed=1, iter=400, chains=4, warmup=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fit_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_time = fit_time.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(aa_time['log_lik'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psis import psisloo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood2 = aa_time['log_lik'].reshape(1200,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loo2, loos2, ks2 = psisloo(log_likelihood2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-value are larger than 0.7 and psis-loo estimate is therefore not applicable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks2[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_hpd(x, hazard, f, ax, color=None, label=None, alpha=0.05):\n",
    "    mean = f(hazard.mean(axis=0))\n",
    "    \n",
    "    percentiles = 100 * np.array([alpha / 2., 1. - alpha / 2.])\n",
    "    hpd = np.percentile(f(hazard), percentiles, axis=0)\n",
    "    \n",
    "    ax.fill_between(x, hpd[0], hpd[1], color=color, alpha=0.25)\n",
    "    ax.step(x, mean, color=color, label=label);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_hazard_t = aa_time['lambda0']\n",
    "base_hazard_t.shape\n",
    "\n",
    "met_hazard_t = aa_time['lambda0'] * np.exp(np.atleast_2d(aa_time['beta']))\n",
    "met_hazard.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (hazard_ax, surv_ax) = plt.subplots(ncols=2, sharex=True, sharey=False, figsize=(16, 6))\n",
    "\n",
    "plot_with_hpd(interval_bounds[:-1], met_hazard_t, cum_hazard,\n",
    "              hazard_ax, color=blue, label='Standard')\n",
    "plot_with_hpd(interval_bounds[:-1], base_hazard_t, cum_hazard,\n",
    "              hazard_ax, color=red, label='TEST')\n",
    "\n",
    "\n",
    "hazard_ax.set_xlim(0, df.t.max());\n",
    "hazard_ax.set_ylim(0, 11);\n",
    "\n",
    "hazard_ax.set_xlabel('Days');\n",
    "\n",
    "hazard_ax.set_ylabel(r'Cumulative hazard, $\\int_0^t \\lambda(u)du$');\n",
    "hazard_ax.legend(loc=2);\n",
    "\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "\n",
    "plot_with_hpd(interval_bounds[1:], base_hazard_t, survival,\n",
    "              surv_ax, color=red)\n",
    "plot_with_hpd(interval_bounds[1:], met_hazard_t, survival,\n",
    "              surv_ax, color=blue)\n",
    "survivalstan.utils.plot_observed_survival(df=df[df['skill_gap'] == 0], event_col='dead', time_col='t', label='standard')\n",
    "survivalstan.utils.plot_observed_survival(df=df[df['skill_gap'] == 1], event_col='dead', time_col='t', label='test')\n",
    "\n",
    "surv_ax.set_xlim(0, df.t.max());\n",
    "surv_ax.set_xlabel('Days');\n",
    "\n",
    "surv_ax.set_ylabel('Survivor function $S(t)$');\n",
    "\n",
    "#fig.suptitle('Bayesian survival model');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
